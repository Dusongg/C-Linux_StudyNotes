#  Golang单机锁

## 锁升级

`sync.Mutex`先“乐观”后“悲观”`

> 乐观锁的CAS实现:
>
> ```go
> func (m *Mutex) Lock() {
>     if atomic.CompareAndSwapInt32(&m.state, 0, mutexLocked) {
>         return
>     }
>     // Slow path (outlined so that the fast path can be inlined)
>     m.lockSlow()
> }
> ```
>
> 

自旋模式转为阻塞模式的具体条件如下：

- 自旋累计达到 4 次仍未取得战果；
- CPU 单核或仅有单个 P 调度器；（此时自旋，其他 goroutine 根本没机会释放锁，自旋纯属空转）；
- 当前 P 的执行队列中仍有待执行的 G. （避免因自旋影响到 GMP 调度效率）.



## 饥饿模式

1. 正常模式

在这种模式下，当前 Goroutine 可以直接尝试获取锁（即便队列中有等待 Goroutine）。如果加锁失败，当前 Goroutine 会加入等待队列。



2. 饥饿模式

- **什么时候切换**：当阻塞队列存在 goroutine 等锁超过 1ms 而不得，则进入饥饿模式；（当阻塞队列已清空，或取得锁的 goroutine 等锁时间已低于 1ms 时，则回到正常模式.）

- **饥饿模式下**，锁的所有权按照阻塞队列的顺序<u>FIFO</u>进行依次传递. 新 goroutine 进行流程时不得抢锁，而是进入队列尾部排队.



## 核心数据结构

```go
	type Mutex struct {
    state int32
    sema  uint32  //用于阻塞和唤醒 goroutine 的信号量.
}
```



Mutex.state:

![image-20250113下午14620494](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250113%E4%B8%8B%E5%8D%8814620494.png)

# 分布式锁

<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250113%E4%B8%8B%E5%8D%8830001841.png" alt="image-20250113下午30001841" style="zoom:50%;" />

- **主动轮询型**：该模型类似于单机锁中的主动轮询 + cas 乐观锁模型，取锁方会持续对分布式锁发出尝试获取动作，如果锁已被占用则会不断发起重试，直到取锁成功为止
-  **watch 回调型**：在取锁方发现锁已被他人占用时，会创建 watcher 监视器订阅锁的释放事件，随后不再发起主动取锁的尝试；当锁被释放后，取锁方能通过之前创建的 watcher 感知到这一变化，然后再重新发起取锁的尝试动作

## [Redis实现](../../Backend/Redis/Redis.md/#7.4 Redis分布式锁)

- **如何避免死锁问题**

  设置过期时间（`SETEX`）——〉务处理流程中的耗时超过了设置的过期时间阈值，锁提前释放 ——〉**redission看门狗策略**

- **弱一致性问题**：

  - 前提：为避免单点故障问题，redis 会基于主从复制的方式实现数据备份. （以哨兵机制为例，哨兵会持续监听 master 节点的健康状况，倘若 master 节点发生故障，哨兵会负责扶持 slave 节点上位，以保证整个集群能够正常对外提供服务）. 此外，在 CAP 体系中，redis 走的是 **AP** 路线，为保证服务的吞吐性能，<u>主从节点之间的数据同步是异步延迟进行的</u>.

  - 问题：在master节点上加锁成功之后，在同步到slave节点之前，master宕机，导致多个线程占有锁
  - 解决方案：`redis 红锁`

### 看门狗(watch dog)策略

<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250114%E4%B8%8B%E5%8D%8814722951.png" alt="image-20250114下午14722951" style="zoom:50%;" />

- **加锁时启动看门狗**

```go
// Lock 加锁.
func (r *RedisLock) Lock(ctx context.Context) (err error) {
    defer func() {
        if err != nil {
            return
        }
        // 加锁成功的情况下，会启动看门狗
        // 关于该锁本身是不可重入的，所以不会出现同一把锁下看门狗重复启动的情况
        r.watchDog(ctx)
    }()
    // ...
}
```

```go
// 启动看门狗
func (r *RedisLock) watchDog(ctx context.Context) {
    // 1. 非看门狗模式，不处理
    if !r.watchDogMode {
        return
    }


    // 2. 确保之前启动的看门狗已经正常回收
    for !atomic.CompareAndSwapInt32(&r.runningDog, 0, 1) {
    }


    // 3. 启动看门狗
    ctx, r.stopDog = context.WithCancel(ctx)
    go func() {
        defer func() {
            atomic.StoreInt32(&r.runningDog, 0)
        }()
        r.runWatchDog(ctx)
    }()
}
```

```go
func (r *RedisLock) runWatchDog(ctx context.Context) {
    ticker := time.NewTicker(WatchDogWorkStepSeconds * time.Second)
    defer ticker.Stop()


    for range ticker.C {
        select {
        case <-ctx.Done():
            return
        default:
        }


        // 看门狗负责在用户未显式解锁时，持续为分布式锁进行续期
        // 通过 lua 脚本，延期之前会确保保证锁仍然属于自己
        _ = r.DelayExpire(ctx, WatchDogWorkStepSeconds)
    }
}
```



- **解锁时停止看门狗**

```go
// Unlock 解锁. 基于 lua 脚本实现操作原子性.
func (r *RedisLock) Unlock(ctx context.Context) (err error) {
    defer func() {
        if err != nil {
            return
        }


        // 停止看门狗
        if r.stopDog != nil {
            r.stopDog()
        }
    }()


    // ...
}
```



### 红锁（redlock）

<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250114%E4%B8%8B%E5%8D%8825758017.png" alt="image-20250114下午25758017" style="zoom:50%;" />

• 我们假定集群中有 2N+1个 redis 节点（通常将节点总数设置为奇数，有利于多数派原则的执行效率）

• 这些 redis 节点彼此间是相互独立的，不存在从属关系

• 每次客户端尝试进行加锁操作时，会同时对2N+1个节点发起加锁请求

• 每次客户端向一个节点发起加锁请求时，会设定一个很小的请求处理超时阈值

• 客户端依次对2N+1个节点发起加锁请求，只有在小于请求处理超时阈值的时间内完成了加锁操作，才视为一笔加锁成功的请求

• 过完2N+1个节点后，统计加锁成功的请求数量

• <u>倘若加锁请求成功数量大于等于N+1（多数派），则视为红锁加锁成功</u>

• <u>倘若加锁请求成功数量小于N+1，视为红锁加锁失败，此时会遍历2N+1个节点进行解锁操作</u>，有利于资源回收，提供后续使用方的取锁效率





## MySQL实现

- **Lock**：将锁标识作为表中的唯一键
- **UnLock**：解锁动作可以给予mysql事务保证原子性

## etcd实现

- **如何避免死锁问题**——租约机制

  <img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250113%E4%B8%8B%E5%8D%8880333703.png" alt="image-20250113下午80333703" style="zoom:50%;" />

  1. 用户可以先申请一份租约，设定好租约的截止时间
  2. 异步启动一个续约协程，负责在业务逻辑处理完成前，按照一定的时间节奏持续进行续约操作
  3.  在执行取锁动作，将对应于锁的 kv 数据和租约进行关联绑定，使得锁数据和租约拥有相同的过期时间属性

- **惊群效应**

  倘若一把分布式锁的竞争比较激烈，那么锁的释放事件可能同时被多个的取锁方所监听，一旦锁真的被释放了，所有的取锁方都会一拥而上尝试取锁，对性能造成损耗

  - 解决方法：**前缀 + revision机制**：

    ![image-20250113下午83127287](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20250113%E4%B8%8B%E5%8D%8883127287.png)

    对于同一把分布式锁，取锁方获得一个相同前缀加上身份标识作为key，并获得该前缀下的一个递增版本号`revision`

    判定自身 lock key 对应的 revision 是不是其中最小的，如果是的话，才表示加锁成功

    如果锁被他人占用，取锁方会 watch 监听 revision 小于自己但最接近自己的那个 lock key 的删除事件.

    
