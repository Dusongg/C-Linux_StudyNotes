# 概念

## 1 什么是无锁队列？

- 不使用互斥锁或者信号量，通过原子操作（CAS等）来保证操作的原子性

lock-free或wait-free

## 2 什么场景下使用？

> 无锁队列适合于高并发场景下，特别是在需要频繁进行队列操作的情况下。以下是一些适合使用无锁队列的场景：
>
> 1. **高并发的生产者-消费者模型：** 当有大量的生产者和消费者需要同时访问队列时，使用无锁队列可以减少竞争和锁带来的性能损失，提高整体的吞吐量。
> 2. **事件驱动系统：** 在事件驱动的系统中，多个事件源可能同时向队列中推送事件，多个处理器同时从队列中取出事件进行处理。使用无锁队列可以提高事件的处理效率。
> 3. **数据传输和消息队列：** 在需要高效地进行数据传输和消息传递的场景中，无锁队列可以减少等待和阻塞，提高传输效率。
> 4. **高性能计算：** 在需要进行大量数据处理和计算的高性能计算场景中，无锁队列可以减少线程间的同步和竞争，提高计算效率。
>
> 总的来说，无锁队列适合于需要高效处理大量并发操作的场景，能够提高系统的响应速度和整体性能。不过，使用无锁队列也需要考虑到实现的复杂性和硬件支持的问题，需要根据具体情况进行权衡和选择。

## 3 无锁比有锁效率更高吗

> 无锁队列相对于有锁队列在某些情况下可以提高效率，但并不总是如此。其效率提高主要体现在减少了线程间的竞争和阻塞，以及减少了不必要的上下文切换。
>
> 1. **减少竞争和阻塞：** 在有锁队列中，当一个线程持有锁时，其他线程无法访问队列，必须等待锁释放。而在无锁队列中，由于没有锁的存在，线程可以直接进行操作，减少了竞争和阻塞。
> 2. **减少上下文切换：** 在有锁队列中，线程在等待锁的过程中会被阻塞，需要进行上下文切换到其他线程，而在无锁队列中，线程可以自旋等待直到操作完成，避免了不必要的上下文切换。
>
> 但是，无锁队列并不总是比有锁队列效率高，它也有一些缺点：
>
> 1. **复杂性增加：** 无锁队列的实现比有锁队列要复杂，需要考虑更多的细节和并发情况，容易出错。
> 2. **性能依赖硬件支持：** 无锁队列通常依赖于硬件的原子操作指令（如CAS指令），如果硬件不支持这些指令，则无法实现高效的无锁队列。
>
> 因此，在选择使用有锁队列还是无锁队列时，需要根据具体情况进行评估。一般来说，在高并发和竞争情况下，无锁队列可能会更有效率，但在低并发情况下，有锁队列可能更简单且性能更好。

# lock-free/wait-free/blocking

![image-20240328221451273](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328221451273.png)

- 不能使用blocking的几个场景 —— 程序无法”往前移动“
  1. 信号处理程序
  2. 实时系统

- 需要使用有锁的场景
  1. 耗时计算/耗时IO

> - 问：操作系统底层如何支持C++的atomic的原子操作？
>
> 操作系统底层支持C++的`atomic`原子操作通常通过底层的硬件支持和操作系统提供的原子指令来实现。在现代处理器中，通常会有一些特殊的指令，如`compare-and-swap (CAS)`、`load-link/store-conditional (LL/SC)`等，用于实现原子操作。
>
> 当编译器生成`atomic`操作的代码时，它会使用这些硬件原子指令来确保操作的原子性。在操作系统层面，它会负责管理线程的调度和同步，以确保在多线程环境下`atomic`操作的正确性。操作系统提供的原子操作接口通常会利用底层硬件的原子指令来实现，以保证在多线程环境下对共享数据的原子访问。
>
> 总的来说，操作系统底层支持C++的`atomic`原子操作主要依赖于硬件的原子指令和操作系统提供的同步机制来实现。
>
> 
>
> - 问：比如锁总线嘛？
>
> 是的，底层支持`atomic`操作的方式之一就是通过锁总线的方式来实现。在多核处理器上，为了保证原子性，可以使用锁总线的方式来实现`atomic`操作。
>
> 当一个处理器要执行一个原子操作时，它会发送一个锁请求到总线，这会导致其他处理器暂停对总线的访问，直到该处理器完成操作并释放锁。这样可以保证在多核处理器上对共享数据的原子访问。
>
> 不过，锁总线的方式会导致性能开销较大，因为它会限制了处理器对总线的并发访问。因此，在实际应用中，通常会尽量避免使用锁总线，而是使用更轻量级的原子操作实现，如CAS等。
>
> 
>
> 
>
> - 问：CAS具体是干嘛的呢
>
> CAS（Compare and Swap）是一种原子操作，用于实现多线程环境下的并发控制。它的基本思想是：比较并交换。CAS操作包含三个操作数：一个内存位置（通常是一个地址）、旧的预期值和一个新值。如果内存位置的值与旧的预期值相匹配，那么将该位置的值更新为新值，否则不做任何操作。
>
> CAS操作通常用于实现无锁数据结构和并发算法，比如无锁队列、无锁哈希表等。它能够确保在多线程环境下对共享数据的原子访问，而不需要使用传统的互斥锁来实现线程同步。这样可以提高并发性能，减少线程阻塞和上下文切换的开销。
>
> 总的来说，CAS是一种轻量级的

# 无锁队列——MPSC——wait_free

- 生产者

![image-20240328215416791](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328215416791.png)



- 消费者

<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328220225253.png" alt="image-20240328220225253" >

`Node* tail = _tail.load(std::memory_order_relaxed)`为什么这里用relaxed？

- 与第二句有依赖关系，前面的relaxed不会优化到第二句后面



```cpp
#ifndef _MARK_MPSC_QUEUE_H
#define _MARK_MPSC_QUEUE_H

#include <atomic>
#include <utility>

template<typename T>
class MPSCQueueNonIntrusive
{
public:
    MPSCQueueNonIntrusive() : _head(new Node()), _tail(_head.load(std::memory_order_relaxed))
    {
        Node* front = _head.load(std::memory_order_relaxed);
        front->Next.store(nullptr, std::memory_order_relaxed);
    }

    ~MPSCQueueNonIntrusive()
    {
        T* output;
        while (Dequeue(output))
            delete output;

        Node* front = _head.load(std::memory_order_relaxed);
        delete front;
    }

// wait-free
    void Enqueue(T* input)
    {
        Node* node = new Node(input);
        Node* prevHead = _head.exchange(node, std::memory_order_acq_rel);
        prevHead->Next.store(node, std::memory_order_release);
    }

    bool Dequeue(T*& result)
    {
        Node* tail = _tail.load(std::memory_order_relaxed);
        Node* next = tail->Next.load(std::memory_order_acquire);
        if (!next)
            return false;

        result = next->Data;
        _tail.store(next, std::memory_order_release);
        delete tail;
        return true;
    }

private:
    struct Node
    {
        Node() = default;
        explicit Node(T* data) : Data(data)
        {
            Next.store(nullptr, std::memory_order_relaxed);
        }

        T* Data;
        std::atomic<Node*> Next;
    };

    std::atomic<Node*> _head;
    std::atomic<Node*> _tail;

    MPSCQueueNonIntrusive(MPSCQueueNonIntrusive const&) = delete;
    MPSCQueueNonIntrusive& operator=(MPSCQueueNonIntrusive const&) = delete;
};

template<typename T, std::atomic<T*> T::* IntrusiveLink>
class MPSCQueueIntrusive
{
public:
    MPSCQueueIntrusive() : _dummyPtr(reinterpret_cast<T*>(std::addressof(_dummy))), _head(_dummyPtr), _tail(_dummyPtr)
    {
        // _dummy is constructed from aligned_storage and is intentionally left uninitialized (it might not be default constructible)
        // so we init only its IntrusiveLink here
        std::atomic<T*>* dummyNext = new (&(_dummyPtr->*IntrusiveLink)) std::atomic<T*>();
        dummyNext->store(nullptr, std::memory_order_relaxed);
    }

    ~MPSCQueueIntrusive()
    {
        T* output;
        while (Dequeue(output))
            delete output;
    }

    void Enqueue(T* input)
    {
        (input->*IntrusiveLink).store(nullptr, std::memory_order_release);
        T* prevHead = _head.exchange(input, std::memory_order_acq_rel);
        (prevHead->*IntrusiveLink).store(input, std::memory_order_release);
    }

    bool Dequeue(T*& result)
    {
        T* tail = _tail.load(std::memory_order_relaxed);
        T* next = (tail->*IntrusiveLink).load(std::memory_order_acquire);
        if (tail == _dummyPtr)
        {
            if (!next)
                return false;

            _tail.store(next, std::memory_order_release);
            tail = next;
            next = (next->*IntrusiveLink).load(std::memory_order_acquire);
        }

        if (next)
        {
            _tail.store(next, std::memory_order_release);
            result = tail;
            return true;
        }

        T* head = _head.load(std::memory_order_acquire);
        if (tail != head)
            return false;

        Enqueue(_dummyPtr);
        next = (tail->*IntrusiveLink).load(std::memory_order_acquire);
        if (next)
        {
            _tail.store(next, std::memory_order_release);
            result = tail;
            return true;
        }
        return false;
    }

private:
    std::aligned_storage_t<sizeof(T), alignof(T)> _dummy;
    T* _dummyPtr;
    std::atomic<T*> _head;
    std::atomic<T*> _tail;

    MPSCQueueIntrusive(MPSCQueueIntrusive const&) = delete;
    MPSCQueueIntrusive& operator=(MPSCQueueIntrusive const&) = delete;
};

template<typename T, std::atomic<T*> T::* IntrusiveLink = nullptr>
using MPSCQueue = std::conditional_t<IntrusiveLink != nullptr, MPSCQueueIntrusive<T, IntrusiveLink>, MPSCQueueNonIntrusive<T>>;

#endif // MPSCQueue_h__

```



# lock_free

```cpp
#include <atomic>
#include <memory>

template <typename T>
class LockFreeQueue {
private:
    struct Node {
        std::shared_ptr<T> data;
        Node* next;
        Node() : next(nullptr) {}
    };

    std::atomic<Node*> head;
    std::atomic<Node*> tail;

public:
    LockFreeQueue() : head(new Node), tail(head.load()) {}

    void push(T item) {
        std::shared_ptr<T> newData(std::make_shared<T>(std::move(item)));
        Node* newNode = new Node;
        Node* currentTail = nullptr;
        while (true) {
            currentTail = tail.load();
            if (tail.compare_exchange_weak(currentTail, newNode)) {
                break;
            }
        }
        currentTail->data.swap(newData);
        currentTail->next = newNode;
    }

    std::shared_ptr<T> pop() {
        Node* currentHead = nullptr;
        while (true) {
            currentHead = head.load();
            if (currentHead == tail.load()) {
                return std::shared_ptr<T>();
            }
            Node* newHead = currentHead->next;
            if (head.compare_exchange_weak(currentHead, newHead)) {
                std::shared_ptr<T> res(currentHead->data);
                delete currentHead;
                return res;
            }
        }
    }
};

```

