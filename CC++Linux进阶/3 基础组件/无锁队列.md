# 概念

## 1 什么是无锁队列？

- 不使用互斥锁或者信号量，通过原子操作（CAS等）来保证操作的原子性

## 2 什么场景下使用？

> 无锁队列适合于高并发场景下，特别是在需要频繁进行队列操作的情况下。以下是一些适合使用无锁队列的场景：
>
> 1. **高并发的生产者-消费者模型：** 当有大量的生产者和消费者需要同时访问队列时，使用无锁队列可以减少竞争和锁带来的性能损失，提高整体的吞吐量。
> 2. **事件驱动系统：** 在事件驱动的系统中，多个事件源可能同时向队列中推送事件，多个处理器同时从队列中取出事件进行处理。使用无锁队列可以提高事件的处理效率。
> 3. **数据传输和消息队列：** 在需要高效地进行数据传输和消息传递的场景中，无锁队列可以减少等待和阻塞，提高传输效率。
> 4. **高性能计算：** 在需要进行大量数据处理和计算的高性能计算场景中，无锁队列可以减少线程间的同步和竞争，提高计算效率。
>
> 总的来说，无锁队列适合于需要高效处理大量并发操作的场景，能够提高系统的响应速度和整体性能。不过，使用无锁队列也需要考虑到实现的复杂性和硬件支持的问题，需要根据具体情况进行权衡和选择。

## 3 无锁比有锁效率更高吗

> 无锁队列相对于有锁队列在某些情况下可以提高效率，但并不总是如此。其效率提高主要体现在减少了线程间的竞争和阻塞，以及减少了不必要的上下文切换。
>
> 1. **减少竞争和阻塞：** 在有锁队列中，当一个线程持有锁时，其他线程无法访问队列，必须等待锁释放。而在无锁队列中，由于没有锁的存在，线程可以直接进行操作，减少了竞争和阻塞。
> 2. **减少上下文切换：** 在有锁队列中，线程在等待锁的过程中会被阻塞，需要进行上下文切换到其他线程，而在无锁队列中，线程可以自旋等待直到操作完成，避免了不必要的上下文切换。
>
> 但是，无锁队列并不总是比有锁队列效率高，它也有一些缺点：
>
> 1. **复杂性增加：** 无锁队列的实现比有锁队列要复杂，需要考虑更多的细节和并发情况，容易出错。
> 2. **性能依赖硬件支持：** 无锁队列通常依赖于硬件的原子操作指令（如CAS指令），如果硬件不支持这些指令，则无法实现高效的无锁队列。
>
> 因此，在选择使用有锁队列还是无锁队列时，需要根据具体情况进行评估。一般来说，在高并发和竞争情况下，无锁队列可能会更有效率，但在低并发情况下，有锁队列可能更简单且性能更好。

# lock-free/wait-free/blocking

![image-20240328221451273](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328221451273.png)

> 1. **Lock-free（无锁）：** Lock-free 是指在并发编程中，算法或数据结构能够在没有使用显式锁的情况下保证多线程的正确性。换句话说，即使在有线程因为某些原因被阻塞时，其他线程仍然可以继续执行并完成其操作，不会导致死锁或饥饿。Lock-free 的实现通常使用原子操作来实现，比如 CAS（Compare and Swap）操作。
> 2. **Wait-free（无等待）：** Wait-free 是 Lock-free 的一个更严格的子集，它要求在任何情况下，所有线程都能在有限步数内完成其操作。换句话说，即使有线程在执行时被中断或竞争，其他线程也能够继续向前执行而不需要等待。Wait-free 算法通常更复杂，并且可能会牺牲一些性能来实现这种强硬性。

- 不能使用blocking的几个场景 —— 程序无法”往前移动“
  1. 信号处理程序
  2. 实时系统

- 需要使用有锁的场景
  1. 耗时计算/耗时IO

> - 问：操作系统底层如何支持C++的atomic的原子操作？
>
> 操作系统底层支持C++的`atomic`原子操作通常通过底层的硬件支持和操作系统提供的原子指令来实现。在现代处理器中，通常会有一些特殊的指令，如`compare-and-swap (CAS)`、`load-link/store-conditional (LL/SC)`等，用于实现原子操作。
>
> 当编译器生成`atomic`操作的代码时，它会使用这些硬件原子指令来确保操作的原子性。在操作系统层面，它会负责管理线程的调度和同步，以确保在多线程环境下`atomic`操作的正确性。操作系统提供的原子操作接口通常会利用底层硬件的原子指令来实现，以保证在多线程环境下对共享数据的原子访问。
>
> 总的来说，操作系统底层支持C++的`atomic`原子操作主要依赖于硬件的原子指令和操作系统提供的同步机制来实现。
>
> 
>
> - 问：比如锁总线嘛？
>
> 是的，底层支持`atomic`操作的方式之一就是通过锁总线的方式来实现。在多核处理器上，为了保证原子性，可以使用锁总线的方式来实现`atomic`操作。
>
> 当一个处理器要执行一个原子操作时，它会发送一个锁请求到总线，这会导致其他处理器暂停对总线的访问，直到该处理器完成操作并释放锁。这样可以保证在多核处理器上对共享数据的原子访问。
>
> 不过，锁总线的方式会导致性能开销较大，因为它会限制了处理器对总线的并发访问。因此，在实际应用中，通常会尽量避免使用锁总线，而是使用更轻量级的原子操作实现，如CAS等。
>
> 
>
> 
>
> - 问：CAS具体是干嘛的呢
>
> CAS（Compare and Swap）是一种原子操作，用于实现多线程环境下的并发控制。它的基本思想是：比较并交换。CAS操作包含三个操作数：一个内存位置（通常是一个地址）、旧的预期值和一个新值。如果内存位置的值与旧的预期值相匹配，那么将该位置的值更新为新值，否则不做任何操作。
>
> CAS操作通常用于实现无锁数据结构和并发算法，比如无锁队列、无锁哈希表等。它能够确保在多线程环境下对共享数据的原子访问，而不需要使用传统的互斥锁来实现线程同步。这样可以提高并发性能，减少线程阻塞和上下文切换的开销。
>
> 总的来说，CAS是一种轻量级的

# 无锁队列——MPSC——wait_free

- 生产者(多)

![image-20240328215416791](https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328215416791.png)

- 消费者（单）

<img src="https://typora-dusong.oss-cn-chengdu.aliyuncs.com/image-20240328220225253.png" alt="image-20240328220225253" >

`Node* tail = _tail.load(std::memory_order_relaxed)`为什么这里用relaxed？

- 与第二句有依赖关系，前面的relaxed不会优化到第二句后面



```cpp
#ifndef _MARK_MPSC_QUEUE_H
#define _MARK_MPSC_QUEUE_H

#include <atomic>
#include <utility>

template<typename T>
class MPSCQueueNonIntrusive
{
public:
    MPSCQueueNonIntrusive() : _head(new Node()), _tail(_head.load(std::memory_order_relaxed))
    {
        Node* front = _head.load(std::memory_order_relaxed);
        front->Next.store(nullptr, std::memory_order_relaxed);
    }

    ~MPSCQueueNonIntrusive()
    {
        T* output;
        while (Dequeue(output))
            delete output;

        Node* front = _head.load(std::memory_order_relaxed);
        delete front;
    }

// wait-free
    void Enqueue(T* input)
    {
        Node* node = new Node(input);
        Node* prevHead = _head.exchange(node, std::memory_order_acq_rel);
        prevHead->Next.store(node, std::memory_order_release);
    }

    bool Dequeue(T*& result)
    {
        Node* tail = _tail.load(std::memory_order_relaxed);
        Node* next = tail->Next.load(std::memory_order_acquire);
        if (!next)
            return false;

        result = next->Data;
        _tail.store(next, std::memory_order_release);
        delete tail;
        return true;
    }

private:
    struct Node
    {
        Node() = default;
        explicit Node(T* data) : Data(data)
        {
            Next.store(nullptr, std::memory_order_relaxed);
        }

        T* Data;
        std::atomic<Node*> Next;
    };

    std::atomic<Node*> _head;
    std::atomic<Node*> _tail;

    MPSCQueueNonIntrusive(MPSCQueueNonIntrusive const&) = delete;
    MPSCQueueNonIntrusive& operator=(MPSCQueueNonIntrusive const&) = delete;
};

template<typename T, std::atomic<T*> T::* IntrusiveLink>
class MPSCQueueIntrusive
{
public:
    MPSCQueueIntrusive() : _dummyPtr(reinterpret_cast<T*>(std::addressof(_dummy))), _head(_dummyPtr), _tail(_dummyPtr)
    {
        // _dummy is constructed from aligned_storage and is intentionally left uninitialized (it might not be default constructible)
        // so we init only its IntrusiveLink here
        std::atomic<T*>* dummyNext = new (&(_dummyPtr->*IntrusiveLink)) std::atomic<T*>();
        dummyNext->store(nullptr, std::memory_order_relaxed);
    }

    ~MPSCQueueIntrusive()
    {
        T* output;
        while (Dequeue(output))
            delete output;
    }

    void Enqueue(T* input)
    {
        (input->*IntrusiveLink).store(nullptr, std::memory_order_release);
        T* prevHead = _head.exchange(input, std::memory_order_acq_rel);
        (prevHead->*IntrusiveLink).store(input, std::memory_order_release);
    }

    bool Dequeue(T*& result)
    {
        T* tail = _tail.load(std::memory_order_relaxed);
        T* next = (tail->*IntrusiveLink).load(std::memory_order_acquire);
        if (tail == _dummyPtr)
        {
            if (!next)
                return false;

            _tail.store(next, std::memory_order_release);
            tail = next;
            next = (next->*IntrusiveLink).load(std::memory_order_acquire);
        }

        if (next)
        {
            _tail.store(next, std::memory_order_release);
            result = tail;
            return true;
        }

        T* head = _head.load(std::memory_order_acquire);
        if (tail != head)
            return false;

        Enqueue(_dummyPtr);
        next = (tail->*IntrusiveLink).load(std::memory_order_acquire);
        if (next)
        {
            _tail.store(next, std::memory_order_release);
            result = tail;
            return true;
        }
        return false;
    }

private:
    std::aligned_storage_t<sizeof(T), alignof(T)> _dummy;
    T* _dummyPtr;
    std::atomic<T*> _head;
    std::atomic<T*> _tail;

    MPSCQueueIntrusive(MPSCQueueIntrusive const&) = delete;
    MPSCQueueIntrusive& operator=(MPSCQueueIntrusive const&) = delete;
};

template<typename T, std::atomic<T*> T::* IntrusiveLink = nullptr>
using MPSCQueue = std::conditional_t<IntrusiveLink != nullptr, MPSCQueueIntrusive<T, IntrusiveLink>, MPSCQueueNonIntrusive<T>>;

#endif // MPSCQueue_h__

```



# lock_free

```cpp
#include <atomic>
#include <memory>

template <typename T>
class LockFreeQueue {
private:
    struct Node {
        std::shared_ptr<T> data;
        Node* next;
        Node() : next(nullptr) {}
    };

    std::atomic<Node*> head;
    std::atomic<Node*> tail;

public:
    LockFreeQueue() : head(new Node), tail(head.load()) {}

    void push(T item) {
        //tail指向将要插入的位置,tail本身不存放数据
        //lock_free
        std::shared_ptr<T> newData(std::make_shared<T>(std::move(item)));
        Node* newNode = new Node;
        Node* currentTail = nullptr;
        while (true) {
            currentTail = tail.load();
            if (tail.compare_exchange_weak(currentTail, newNode)) {
                break;
            }
        }
        currentTail->data.swap(newData);
        currentTail->next = newNode;
        //currentTail->next.store(newNode, std::memory_order_release);  两者区别
        
        /*
        //wait_free
        std::shared_ptr<T> newData(std::make_shared<T>(std::move(item)));
        Node* newnode = new Node;
        //改代码不能保证最后两句代码之前prevTail没有被修改，从而影响程序的正确性
        Node* prevTail = tail.exchange(newnode, std::memory_order_acq_rel);
        prevTail->data.swap(newData);
        prevTail->next.store(newnode, std::memory_order_release);
        */
        
        //改正后的wait_free
        
        void push(T item) {
    std::shared_ptr<T> newData(std::make_shared<T>(std::move(item)));
    Node* newNode = new Node;
    Node* currentTail = nullptr;
    Node* prevTail = nullptr;
    while (true) {
        currentTail = tail.load();
        prevTail = tail.exchange(newNode, std::memory_order_acq_rel);
        if (currentTail == prevTail) {
            break;
        } else {
            // 还原tail指针
            tail.store(prevTail, std::memory_order_release);
        }
    }
    prevTail->data.swap(newData);
    prevTail->next.store(newNode, std::memory_order_release);
}

    }

    std::shared_ptr<T> pop() {
        Node* currentHead = nullptr;
        while (true) {
            currentHead = head.load();
            if (currentHead == tail.load()) {
                return std::shared_ptr<T>();
            }
            Node* newHead = currentHead->next;
            if (head.compare_exchange_weak(currentHead, newHead)) {
                std::shared_ptr<T> res(currentHead->data);
                delete currentHead;
                return res;
            }
        }
    }
};

```

## 如何将push操作实现成wait_free呢

要将 `push` 操作实现为 wait-free，需要确保每个线程在有限步骤内能够完成操作。对于 `push` 操作来说，可以采取以下方法：

1. **使用 `exchange`：** 在 `push` 操作中，使用 `exchange` 替换 `tail` 指针，并在替换成功后将数据插入队列。但是，在使用 `exchange` 后需要检查 `tail` 指针是否已经被其他线程更新，如果是，则需要将 `tail` 指针还原，并重新尝试。
2. **添加版本号或时间戳：** 可以给每个节点添加一个版本号或时间戳，每次插入新节点时，都会递增版本号或设置时间戳。在 `push` 操作中，首先保存当前的 `tail` 指针和版本号，然后使用 `exchange` 将新节点插入队列，最后检查 `tail` 指针和版本号是否一致，如果不一致则表示操作失败，需要重试。

这样的实现方式可以保证每个线程在有限步骤内完成 `push` 操作，从而符合 wait-free 的定义。不过需要注意的是，添加版本号或时间戳会增加节点的大小和复杂性，可能会影响性能。

## `compare_exchange_weak`

```cpp
bool compare_exchange_weak(T& expected, T desired, std::memory_order order = std::memory_order_seq_cst) noexcept;
```

如果当前对象的值等于 `expected`，则将当前对象的值修改为 `desired`，并返回 `true`；否则，将 `expected` 更新为当前对象的值，并返回 `false`。这个操作是原子的，能够在多线程环境下确保操作的原子性。



## `exchange`

```cpp
T exchange(T desired, std::memory_order order = std::memory_order_seq_cst) volatile noexcept;
T exchange(T desired, std::memory_order order = std::memory_order_seq_cst) noexcept;
```

这个方法接受一个新值 `desired` 和一个内存顺序 `order`，将原子对象的值替换为 `desired`，并返回替换前的值。`order` 参数指定了内存操作的顺序，控制了内存访问的顺序和一致性。

## 关于是否使用store的区别

在无锁队列的实现中，`currentTail->next = newNode;` 和 `currentTail->next.store(newNode, std::memory_order_release);` 在功能上是等价的，都是将 `newNode` 赋值给 `currentTail` 节点的 `next` 指针。但是，它们在内存模型上有一些微妙的区别：

1. **内存语义：**
   - `currentTail->next = newNode;` 这种写法是直接的内存写操作，编译器会根据上下文选择合适的内存屏障（Memory Barrier）指令，保证 `next` 节点在被其他线程访问时能够看到正确的值。
   - `currentTail->next.store(newNode, std::memory_order_release);` 使用了显式的内存顺序（memory order），在本例中是 `memory_order_release`，它会生成一个相应的内存屏障指令，保证在 `store` 操作之前的所有内存操作都在 `store` 操作之前完成。
2. **可读性和健壮性：**
   - 使用 `store` 显式指定内存顺序可以增强代码的可读性，清晰地表达了程序员的意图。
   - 显式指定内存顺序可以使代码更健壮，可以防止由于不同平台或编译器的优化行为而引起的问题。
